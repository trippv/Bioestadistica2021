---
title: "Comparación de dos medias: Prueba de de Student"
author: "Miguel Tripp"
date: "2021-05-29"
output: 
  workflowr::wflow_html:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_section: true
    theme: cerulean
    code_folding: show 
editor_options:
  chunk_output_type: console
---

```{r}
library(webr)
library(patchwork)
library(tidyverse)
```


# Distribución T


La distribución T-student se asemeja en gran medida a la distribución normal. Tiene como parámetros la media, la varianza y además incorpora a través de los grados de libertad una modificación que permite flexibilizar las colas en función del tamaño que tenga la muestra. A medida que se reduce el tamaño muestral, la probabilidad acumulada en las colas aumenta, siendo así menos estricta de lo cabría esperar en una distribución normal. Una distribución T-student con 30 o más grados de libertad es prácticamente igual a una distribución normal.

```{r, echo=FALSE, message=FALSE, fig.width=10}
par(mfrow = c(1,3))

curve(dnorm(x), -4, 4, col = "darkblue")
curve(dt(x, df = 2), add = TRUE)
mtext("grados libertad = 1 ", side = 3)

curve(dnorm(x), -4, 4, col = "darkblue")
curve(dt(x, df = 5), add = TRUE)
mtext("grados libertad = 5 ", side = 3)

curve(dnorm(x), -4, 4, col = "darkblue")
curve(dt(x, df = 20), add = TRUE)
mtext("grados libertad = 20 ", side = 3)


dev.off()
```



# Comparación de dos medias con t de Student

La prueba t estima la diferencia entre la media de dos grupos usando la proporción de la diferencía entre la media de los grupos y el error estandar de ambos grupos

## Supuestos de la prueba

Para esta prueba es necesario considerar el nivel de medición de las variables, para lo cual se requiere de una variable **cuantitativa** y una variable **nominal** (dos grupos).

Las condiciones para calcular intervalos de confianza o aplicar un test basados en la distribución *T-student* son:

-   **Independencia:** Las observaciones tienen que ser independientes unas de las otras. Para ello el muestreo tiene que ser aleatoria y el tamaño de la muestra inferior al 10% de la población.
-   **Normalidad:** Las poblaciones que se comparan tienn que distribuirse de forma normal. En caso de cierta asimetría, *los T-test son considerablemente robustos cuando el tamaño de muestra es mayor o igual a 30*.
-   **Homogeneidad de varianzas**: La varianza de ambas poblaciones comparadas debe ser igual. En caso de no cumplirse con esta condición se puede usar una prueba *Welch Two Sample t-test*. Esta corrección se incorpora a traves de los grados de libertad permitiendo compensar la diferencia de varianzas (con el inconveniente de que se pierde precisión).

## Establecer las hipótesis

La hopótesis nula ($H_0$) considera que no hay diferencia o cambio. Suele contener en su definición el simbolo $=$ de manera que al comparar dos medias independientes, suponemos que $\mu_1 = \mu_2$. La hipotesis alternativa ($H_A$) considera que el valor real de las medias de ambas poblaciones son diferentes, de manera que $\mu_1 \ne \mu_2$

## Determinar el tipo de test; una o dos colas

Los test de hipótesis pueden ser de una cola o de dos colas. Si la hipótesis alternativa emplea `>` o `<` se trata de un test de una cola, en el que solo se analizan desviaciones en un sentido. Si la hipótesis alternativa es del tipo "diferente de" se trata de un test de dos colas, en el que se analizan posibles desviaciones en las dos direcciones. Solo se emplean test de una cola cuando se sabe con seguridad que las desviaciones de interés son en un sentido y únicamente si se ha determinado antes de observar la muestra, no a posteriori.


## Formula

$t = \frac{\tilde{x}_1 - \tilde{x}_2}   {\sqrt{ \frac{S^2_{1}}{n_{1}} + \frac{S^2_{2}}{n_{2}} }}$   


Donde _t_ es es valor _t_, $\tilde{x}_1$ y $\tilde{x}_2$ son las mediates de los grupos contrastados, $S_1$ y $S_2$ son las desviaciones estandar de cada grupo, y $n_1$ y $n_2$ es el número de observaciones en cada grupo.


Un valor de t grande indicaria que la diferencia entre la media de los grupos es mayor que la desviación estandar de ambos grupos, indicando una diferencia entre ambos grupos. 

Posteriormente comparamos el valor t calculado contra valores de probabilidad.

El nivel de significancia **$\alpha$** determina la probabilidad de error que se quiere asumir a la hora de rechazar la hipótesis nula. Se emplea como punto de referencia para determinar si el valor p obtenido en el test de hipótesis es suficientemente bajo como para considerar significativas las diferencias observadas y por lo tanto rechazar **$H_0$**. 


# Ejemplo (manual):

Se quiere estudiar el efecto de un aditivo en el consumo de alimento en una dieta de peces, para ello, se mide la ingesta de comida (gr) en dos grupos de peces. En vista de los resultados ¿se puede conisderar que el aditivo funciona en la tasa de ingesta?



```{r, echo=FALSE}
set.seed(123)
ctrl <- runif(22, min = 10, max = 36)
treat <- runif(22, min = 10, max = 65)

mean_ctrl <- round(mean(ctrl), 3)
mean_treat <- round(mean(treat), 3)


diff <- mean_ctrl - mean_treat

sd_control <- round(sd(ctrl), 3)
sd_treat <- round(sd(treat), 3)


```




| Grupo       | Media | S     | n   |
|-------------|-------|-------|-----|
| control     | `r mean_ctrl` | `r sd_control` | 22  |
| tratamiento | `r mean_treat` | `r sd_treat`  | 22  |


: Resultados del experimento


**1. Planteamos las hipótesis**

$H_0:$ No hay diferencias entre las medias; _media control - media tratamiento_ $= 0$

$H_a:$ Hay diferencias entre las medias; _media control - media tratamiento_ $\ne 0$


**2. Páramtetro estimado**

media control - media tratamiento = `r mean_ctrl` - `r mean_treat` = `r mean_ctrl - mean_treat`

**4. Modelo de la prueba**

Como queremos evaluar si hay diferencias por las dietas (que puede ser positiva o negativa) usamos una prueba de dos colas

**5. Nivel de significancia**

$\alpha = 0.05$

**6. Estimación del valor p**

Parametro estimado = `r mean_ctrl - mean_treat`

Grados de libertad = 21

SE(media control - media tratamiento) =


$SEM = \sqrt{ \frac{S^2_{Control}}{n_{control}} + \frac{S^2_{tratamiento}}{n_{tratamiento}} }$

Si lo reemplazamos:


SEM = sqrt((`r sd_control`^2 / 22) + (`r sd_treat`^2 / 22))


```{r, echo =FALSE}
SE <- sqrt((sd_control^2 / 22) + (sd_treat^2 / 22))
SE
```

Estimación del valor T 

T = `r mean_treat` - `r mean_ctrl` / `r SE`

```{r, echo = FALSE}
T <- diff / SE 
T
```

Por último, estimamos el valor de probabilidad
```{r}

2*pt(-abs(T), df=42)
```

```{r, echo=FALSE}
plot(t.test(ctrl, treat, var.equal = TRUE))
```



Para aplicar la prueba de t de Student en R, es posible utilizar la función `t.test()` la cual esta incluida en R base y utiliza la siguiente syntaxis:

(a)   `t.test(x, y , alternative = c("two.sided", "less", "greater"), mu = 0, 
        paired = FALSE, var.equal = FALSE, conf.level = 0.95)`

(b)   `t.test(variable1 ~ variable2, data = datos, var.equal = TRUE)`


en donde `var.equal=` nosotros indicamos si ambos grupos muestreales tienen varianzas homogeneas o no. 

```{r}
t.test(ctrl, treat, var.equal = TRUE)
```

El resultadod e esta prueba indica:

  1. Idicación de que es lo que se esta comparando (**data**). 
  2. El **valor t**. Es frecuente obtener valores negativos, lo cual esta bien, ya que solo nos interesa el valor absoluto de la diferencía, o la idstancia de 0, sin importat la dirección.
  3. Los **grados de libertad**, los cuales estan relacionados con el tamaño de la muestra e indican cuantos datos "lilbres" estan disponibles para hacer las comparaciones. 
  4. El **valor p** el cual describe la probabilidad de ver un valor t tan extremo o mas como el obtenido por azar. 
  5. La hipotesis alternativa ($H_a$). En este caso, la $H_a$ es que la diferencía entre la media de las muestras no es 0.
  6. **Intervalo de confianza** del 95%. Esto significa que de repetir el muestreo multiples veces, el 95% de las veces la media estaraá contenida en este intervalo. 
  7. La **media** calculada para cada grupo



# Prueba T para una sola muestra

Esta prueba se utiliza cuando se comara la media de una muestra contra una media ($\mu$) conocida o hipotética 

Generalmente, este valor teórico de la media puee venir de un experimento previo o de un valor abitrario.


Para realizar la prueba t de una muestra en R se puede utilizar la función `t.test()` con la siguiente estructura:

```{r, eval = FALSE}
t.test(x, y = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95, ...)
```

en donde:

  *`x`: vector numérico con los datos
  * `alternative`: tipo de hipotesis alterna. Los valores disponibles son `two.sided` cuando la hipótesis alternativa es $x \ne \mu$, `less` para el caso $x < \mu$ y `greater` para el caso $x > \mu$.
  
## Ejercicio: 

Para verificar si el proceso de llenado de bolsa de un alimento seco para cultivo de 500 g esta operando correctamente, se toman aleatoriamente muestras de tamaño de diez bolsas cada 4 horas Una de estas muestars esta compuesta por las siguientes observaciones:

510, 492, 494, 498, 492, 496, 502, 491, 507, 496

Entonces, vamos a responder la pregunta: a un nivel de signifcancia del 5% ¿esta el proceso de llenado de la bolsa llevandose a cabo correctamente?

1. El primer paso consiste en explorar si la muestra viene de una distribución normal.

```{r}
bolsa <- c(510, 492, 494, 498, 492, 496, 502, 491, 507, 496)

# Prueba de normalidad shapiro
shapiro.test(bolsa)
```

Como el valor P de la prueba de Shapiro-Wilk es mayor a 0.05, se puede asumir que la muestra de bolsas proviene de una distribución normal. 

2. Plantear las hipótesis


$H_0: \mu = 500 gr$
$H_A:  \mu \ne 500gr$


3. Realizar la prueba

```{r}
t.test(bolsa, alternative = "two.sided", mu = 500)

plot(t.test(bolsa, alternative = "two.sided", mu = 500))
```


Como el vaor P es mayor al 5% entonces concluimos que no hay evidencia para afirmar que el proceso de llenao no se esta realizando de manera incorrecta. 




# Comparación de dos medias independientes

## Ejemplo 1: ¿Hay diferencia entre la longitud del culmen entre las poblaciones de pingünos?

De la base de datos de pingüinos, queremos ver si **hay diferencias en la longitud del culmen entre entre las poblaciones de _Dream_ y _Biscoe_ de la especie _Adelie_ **



Para esta sesión, necesitaremos tres paquetes:

  * `Tidyverse`: Para usar dplyr y ggplot2
  * `car`: contiene algunas funciones estadisticas
  * `rstatixs`: Contiene funciones estadisticas compatibles con el ambiente de tidyverse (_pipe-friendly_). Puedes conocer mas sobre este paquete [aqui](https://rpkgs.datanovia.com/rstatix/index.html)


```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(car)
library(rstatix)

penguins <- read_csv("data/penguins_size.csv")


# Filtrar especies
pen_Adelie <- penguins %>%
  filter(species == "Adelie", island %in% c("Dream", "Biscoe"))

```



El primer paso es realizar una exploración de los datos y verificar los supuestos de la prueba; la prueba t requiere que los datos tengan una distribución normal y con varianzas iguales.

Grafico de histogramas para visualizar la distribución de los datos entre ambas islas

```{r}
ggplot(pen_Adelie, aes(x = culmen_length_mm, fill = island, col = island))+
  geom_histogram(alpha = 0.3)+
  facet_wrap(~island)+
  labs(y = "frecuencia",
       x = "longitud del culmen (mm)",
       title="Grafico de densidad", 
       fill = "isla", 
       col = "isla")
```


Tambien es posible realizar un **gráfico qq (quantil-quantil)** para evaluar visualmente si la distribución de los datos de ambas islas se asemejan a una distribución normal

```{r}
ggplot(pen_Adelie, aes(sample = culmen_length_mm, col = island))+
  stat_qq()+
  stat_qq_line()+
  facet_grid(.~ island)
```


De acuerdo a los gráficos, es evidente que ambas poblaciones tienen distribuciones muy parecida a la normal. Para validar estos resutlados, realizaremos una prueba de **Shapiro_wilks** para evaluar la significancia de la normalidad. 

El método de **Shapiro-Wilks** es ampliamente recomendado y tiene mayor poder en comparación de K-S. Para conocer mas sobre pruebas de normalidad visita [aqui](https://www.datanovia.com/en/lessons/normality-test-in-r/#shapiro-wilks-normality-test)

```{r}
pin_Ade_shap <- pen_Adelie %>%
  group_by(island) %>%
  shapiro_test(culmen_length_mm) %>%
  print()
```


>La hipótesis nula de esta prueba es que la muestra viene de una población con distribución normal.


Tanto la gráfica de densidad como el qqplot sugieren que los datos cumplen con el supuesto de normalidad. Para validar esta aseveración es necesario realizar la prueba de Shapiro-Wilk. 


El siguiente paso es evaluar el supuesto de homogeneidad de varianzas. Las gráficas de densidades nuevamente nos dan un indicativo visual de la disperción de los datos, pero es posible evaluar la significancia con una prueba de Levene implementada en el paquete `car`:


```{r}
leveneTest(culmen_length_mm ~ island, data = pen_Adelie)
```

```{r}
pen_Adelie %>% 
  levene_test(culmen_length_mm ~ island)
```


La prueba nos dice que las varianzas son homogeneas entre los grupos


El siguiente paso para la exploración de los datos es obtener el promedio de los valores de la longitud del culmen:

```{r warning=FALSE, message=FALSE}
pen_Ade_sum <- pen_Adelie %>%
  group_by(island) %>%
  summarise(promedio = mean(culmen_length_mm),
            desviacion = sd(culmen_length_mm),
            N = n())
pen_Ade_sum
```


De manera alternativa, este procedimiento se puede realizar con ayuda del paquete `rstatix`
```{r}
pen_Ade_sum <- pen_Adelie %>%
  group_by(island) %>%
  get_summary_stats(culmen_length_mm)
pen_Ade_sum
```



Posteriormente, hacemos un boxplot para visualizar los datos:
```{r}
ggplot(pen_Adelie, aes(x = island, y = culmen_length_mm, fill = island))+
  geom_boxplot(outlier.shape = "")+
  geom_point(position = position_jitter(0.1), col = "grey50")+
  theme_light()+
  labs(x = "Isla",
       y = "longitud del culmen (mm)",
       title = "Longitud del culmen por isla en el pingüino Adelie",
       fill = "Isla", col = "Isla")
```



Finalmente, hacemos la prueba t de student. Esta puede realizarse siguiendo el comando base en R `t.test()`

```{r}
t.test(culmen_length_mm ~ island, data = pen_Adelie, var.equal = TRUE )
```
En esta prueba, la **hipótesis nula** es que la media de las dos poblaciones es igual, lo que impricla que la **hipótesis alternativa** es que la diferencia de las medias no es igual a cero. 

En la prueba de hiótesis, se desea aceptar o rechazar la hipotesis nula con ciertos **intervalos de confianza**. Dado que probamos la diferencias entre ambas medias, el intervalo de confianza especifica el intervalo de los valores de esta diferencia.  


Alternativametne podemos usar la prueba implementada en _rstatixs_:
```{r}
pin_Ade_ttest <- pen_Adelie %>%
  t_test(culmen_length_mm ~ island, var.equal = TRUE) %>%
  print()
```

Ahora con la información generada con la prueba, es posible agregar la anotacion a la gráfica

```{r}
p.val = pin_Ade_ttest$p

ggplot(pen_Adelie, aes(x = island, y = culmen_length_mm, fill = island))+
  geom_boxplot(outlier.shape = "")+
  geom_point(position = position_jitter(0.1), col = "grey50")+
  theme_light()+
  labs(x = "Isla",
       y = "longitud del culmen (mm)",
       title = "Longitud del culmen por isla en el pingüino Adelie",
       fill = "Isla", col = "Isla",
       caption = paste0("t-student; p = ", p.val))
```

Tambien es posible visualizar la ditrtibución de probabilidad

```{r}
plot(t.test(culmen_length_mm ~ island, data = pen_Adelie, var.equal = TRUE ))

```


## Ejemplo 2: ¿ Hay diferencia en la longitud de la aleta entre pingünio **_Adelie_** y **_Gentoo_**? 


```{r}
pen_Aleta <- penguins %>%
  filter(species %in% c("Adelie", "Gentoo"))
```


Histograma de frecuencias
```{r}
ggplot(pen_Aleta, aes(x = flipper_length_mm, fill = species, col = species))+
  geom_histogram(alpha = 0.3)+
  facet_wrap(~species)+
  labs(y = "Frecuencia",
       x = "longitud de la aleta (mm)",
       title="Grafico de densidad", 
       fill = "especie", 
       col = "especie")
```


qqplot
```{r}
ggplot(pen_Aleta, aes(sample = flipper_length_mm, col = species))+
  stat_qq()+
  stat_qq_line()+
  facet_grid(.~ species)
```


Prueba de shapiro utilizando el paquete RSTATIX
```{r}
pen_Aleta_shap <- pen_Aleta %>%
  group_by(species) %>%
  shapiro_test(flipper_length_mm) %>%
  print()
```


Distribucion de las varianzas
```{r}
leveneTest(flipper_length_mm ~ species, data = pen_Aleta)
```


Boxplot
```{r}
ggplot(pen_Aleta, aes(x = species, y = flipper_length_mm, fill = species))+
  geom_boxplot()+
  geom_point(position = position_jitter(0.1), col = "grey50")+
  theme_light()+
  labs(x = "Especie",
       y = "longitud de la aleta (mm)",
       title = "Longitud de la aleta por especie",
       fill = "Especie", col = "Especie")
```


Hacemos la prueba T de student

```{r}
t.test(flipper_length_mm ~ species, data = pen_Aleta, var.equal = TRUE)
```



t.student con rstatixs
```{r}
pen_Aleta_ttest <- pen_Aleta %>%
  t_test(flipper_length_mm ~ species, var.equal = TRUE)
pen_Aleta_ttest

```

La prueba nos dice que las medias de ambas poblaciones son diferentes. 


## Ejemplo 3: ¿Hay diferencia en el peso de los pokemon de roca y los de planta?

Para resolver este ejercicio, vamos a hacer uso de la tabla `datasets_pokemon.xls`y `pokemon_extended.csv` para relacionar el tipo y el peso de cada pokemon.

```{r}
poke_ext <- read_csv("data/pokemon_extended.csv")


pokemon <- readxl::read_xls("data/datasets_pokemon.xls")


poke_test <- pokemon %>% 
  inner_join(poke_ext, by = "Name") %>% 
  select(Type1, weight_kg) %>% 
  filter(Type1 %in% c("Grass", "Rock"))
```



Como primer paso, visualizamos los valores de peso de cada grupo con un histograma 
```{r}
poke_hito <- ggplot(poke_test, aes(x = weight_kg, fill = Type1))+
  geom_histogram(alpha = 0.4)+
  facet_wrap(~Type1, nrow = 2)+
  theme(legend.position = "none")
```


y psoteriorment construimos qqplots para cada grupo
```{r}
poke_qq <- ggplot(poke_test, aes(sample = weight_kg, color = Type1))+
  geom_qq()+
  geom_qq_line()+
  facet_wrap(~Type1, nrow = 2)+
  theme(legend.position = "none")


poke_hito + poke_qq
```

Los histogramas muestran que los valores parecen tener una fuerte asimetria y curtosis negativa para el caso del grupo roca. 

Prueba de Shapiro-Wilk
```{r}
poke_test %>% 
  group_by(Type1) %>% 
  shapiro_test(weight_kg)
```
La prueba de Shapiro-Wilk nos confirma que ambos grupos no vienen de una distribución normal.En este caso, es posible hacer una transformación de los datos, para lo cual vamos a generar una columna columna con el logaritmo del peso

```{r}
poke_test$log_weight <- log(poke_test$weight_kg)
poke_test
```

Y volvemos a generar los histogramas de frecuencia y qqplots para ser el cambio

```{r}
poke_hito_log <- ggplot(poke_test, aes(x = log_weight, fill = Type1))+
  geom_histogram(alpha = 0.4)+
  facet_wrap(~Type1, nrow = 2)+
  theme(legend.position = "none")

poke_qq_log <- ggplot(poke_test, aes(sample = log_weight, color = Type1))+
  geom_qq()+
  geom_qq_line()+
  facet_wrap(~Type1, nrow = 2)+
  theme(legend.position = "none")


poke_hito_log + poke_qq_log
```

y repetimos la prueba de normalidad

```{r}
poke_test %>% 
  group_by(Type1) %>% 
  shapiro_test(log_weight)
```

Comprobando que la transformación nos ajusta los datos a una distribución normal.


Posteriormente, realizamos una prueba de Levene para corroborar que los datos tengan homogeneidad de varianzas
```{r}
poke_test %>% 
  levene_test(log_weight ~ Type1)

```


Posteriormente realizamos la prueba t usando los valores transformados
```{r}
t.test(log_weight ~ Type1, data = poke_test)
```

```{r}
plot(t.test(log_weight ~ Type1, data = poke_test))
```



Finalmente, realizamos un boxplot para mostrar las diferencias entre ambos grupos
```{r}
ggplot(poke_test, aes(x = Type1, y = weight_kg, fill = Type1))+
  geom_boxplot()
```

```{r}
ggplot(poke_test, aes(x = Type1, y = log_weight, fill = Type1))+
  geom_boxplot()
```


## Ejemplo 4: ¿Hay diferencia entre la actividad enzimática de la citrato sintasa a 18°C y 32°C?; Prueba t con varianzas heterogeneas

Como ya hemos visto, una de las condiciones para aplicar una prueba t de Student es la igualdad de varianzas (homocedasticidad) de ambas poblaciones. En caso de no cumplirse esta condición se puede emplear un _Welch Two Sample t-test_. Esta corrección se incorpora a través de los grados de libertad permitiendo compensar la diferencia de varianzas. El número de grados de libertad de un Welch Two Sample t-test viene dado por la siguiente función:

$f = \frac{(\frac{S^2_1}{n_1} + \frac{S^2_2}{n_2})^2} {\frac{1}{n_1 + 1}(\frac{S^2_1}{n_1})^2  +  \frac{1}{n_2 + 1}(\frac{S^2_2}{n_2})^2} - 2$



Para este ejercicio, utilizaremos los datos de actividad enzimática de la citrato sintasa (CS) entre una muestra colectada tras una exposición a 18°C y una exposición a 32°C. Estos datos se pueden descargar de la siguiente liga:


```{r, message=FALSE}

cs_url <- "https://raw.githubusercontent.com/trippv/Miguel_Tripp/master/CS_subset.csv"

cs_activity <- read_csv(cs_url)
```

Para este ejercicio vamos a filtrar solamente los datos del **experimento número 4** y de las temperaturas 18 y 32. Posteriomente vamos a convertir estos valores a factores

```{r}
cs_activity <- cs_activity %>% 
  filter(ExpNum== 4,
         TreatTemp %in% c(18,32)) %>% 
  mutate(TreatTemp = factor(TreatTemp))

```

Utilizando rstatix, realizamos las pruebas de normalidad y homogeneidad de varianzas
```{r}
# Prueba de normalidad
cs_activity %>% 
  group_by(TreatTemp) %>% 
  shapiro_test(ActivityCS)

# Prueba de homogeneidad de varianzas
cs_activity %>% 
  levene_test(ActivityCS ~ TreatTemp)

# Boxplot 

ggplot(data = cs_activity, aes(x = TreatTemp, y = ActivityCS, fill = TreatTemp))+
  geom_boxplot()

```

Finalmente realizamos la prueba de Welch incluyendo el parametro `var.equal = FALSE`

```{r}
cs_activity %>% 
  t_test(ActivityCS ~ TreatTemp, var.equal = FALSE)

# alternativamente
t.test(ActivityCS ~ TreatTemp, data = cs_activity, var.equal = FALSE)

plot(t.test(ActivityCS ~ TreatTemp, data = cs_activity, var.equal = FALSE))

```

Finalmente concluimos que no hay diferencia entre la actividad enzimatica tras una exposición a 32°C 

# Comparación de dos medias dependientes

## Ejercicio: ¿Hay diferencia en el consumo de oxígeno ($MO_2$) tras la exposición a la temperatura?


Para esto utilizaremos datos de tasa metabolica de 10 juveniles de abulón azul a 18°C y posteriormente medido tras una exposición aguda a 32°C, es decir **cada invdividuo aparece en ambos grupos**

```{r}
abalone_mo <- "https://raw.githubusercontent.com/trippv/Miguel_Tripp/master/abalone_MO2.csv"

mo2 <- read_csv(abalone_mo)
mo2$Temperatura <- as.factor(mo2$Temperatura)
```



Exploración de los datos con `geom_histogram`
```{r}
ggplot(mo2, aes(x = MO2,fill=Temperatura))+
  geom_histogram()+
  labs(x = "consumo de oxígeno (MO2)")
```

Verificar la normalidad con gráfico de qq seguido con una prueba de Shapiro
```{r}
ggplot(mo2, aes(sample= MO2, col = Temperatura)) +
  stat_qq()+
  stat_qq_line()+
  facet_grid(.~ Temperatura)
  
```


```{r}
mo2_shapiro <- mo2 %>%
  group_by(Temperatura) %>%
  shapiro_test(MO2) %>% 
  print()

```

Ambas gráficas y la prueba indica que uno de los grupos no cumple con el supuesto de normalidad. Dado que el tamaño de la muestra es pequeño, hay que evaluar cual es el mejor procedimiento.

Una opción es analizar cada una de las muestras y evaluar si alguno puede ser considerado como outlier. Otra opcion es realizar una transformación de los datos.

A continuación, se tranformaran los datos de MO2 a logaritmo

```{r}
mo2 <- mo2 %>% 
  mutate(mo2_log = log(MO2))
```

Verificar la normalidad de los datos transformados con gráfico de qq seguido con una prueba de Shapiro
```{r}
ggplot(mo2, aes(sample= mo2_log, col = Temperatura)) +
  stat_qq()+
  stat_qq_line()+
  facet_grid(.~ Temperatura)+
  labs(title = "QQplot de datos transformados")
  
```

Prueba de Shapiro para los datos transformados
```{r}
mo2_log_shapiro <- mo2 %>%
  group_by(Temperatura) %>%
  shapiro_test(mo2_log) %>% 
  print()

```

Prueba de levene para varianzas

```{r}
mo2_log_leven <- mo2 %>%
  levene_test(mo2_log ~ Temperatura) %>% 
  print()

```


Prueba t de student pareada
```{r}
mo2_log_ttest <- mo2 %>%
  t_test(mo2_log ~ Temperatura, paired = TRUE, var.equal = TRUE) %>% 
  print()

```

Y finalmente graficamos los datos
```{r}
ggplot(mo2, aes(x = Temperatura, y = MO2, fill = Temperatura))+
  geom_boxplot(outlier.shape = "")+
  geom_point(col = "grey35")+
  geom_line(aes(group = Individuo), col = "grey35")+
  labs(title = "Cambio en el consumo de oxígeno tras un incremento en la temperatura")
```


